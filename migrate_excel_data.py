#!/usr/bin/env python3
"""
ì—‘ì…€ ë°ì´í„°ë¥¼ PostgreSQLë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
ê¸°ì¡´ Asset Management.xlsx íŒŒì¼ì˜ ë°ì´í„°ë¥¼ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ë¡œ ì´ì „í•©ë‹ˆë‹¤.
"""

import pandas as pd
import psycopg2
from psycopg2.extras import RealDictCursor
import sys
import os
from datetime import datetime
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ExcelToPostgreSQLMigrator:
    def __init__(self, excel_file_path, db_config):
        self.excel_file_path = excel_file_path
        self.db_config = db_config
        self.connection = None
    
    def connect_database(self):
        """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°í•©ë‹ˆë‹¤."""
        try:
            self.connection = psycopg2.connect(**self.db_config)
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
        except psycopg2.Error as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def read_excel_data(self):
        """ì—‘ì…€ íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤."""
        try:
            if not os.path.exists(self.excel_file_path):
                logger.error(f"ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.excel_file_path}")
                return None
            
            # ì—‘ì…€ íŒŒì¼ ì½ê¸°
            df = pd.read_excel(self.excel_file_path)
            logger.info(f"ì—‘ì…€ íŒŒì¼ì—ì„œ {len(df)}ê°œì˜ í–‰ì„ ì½ì—ˆìŠµë‹ˆë‹¤.")
            
            # ì»¬ëŸ¼ëª… í™•ì¸ ë° ë§¤í•‘
            expected_columns = ["ID", "Type", "Model", "Purchase Date", "Warranty", "Status", "Location", "Reason"]
            
            if not all(col in df.columns for col in expected_columns):
                logger.warning("ì¼ë¶€ ì˜ˆìƒ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼:")
                logger.warning(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")
                
                # ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¸ ê²½ìš° ë§¤í•‘ ì‹œë„
                column_mapping = {}
                for expected_col in expected_columns:
                    # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ë§¤í•‘
                    for actual_col in df.columns:
                        if expected_col.lower() == actual_col.lower():
                            column_mapping[expected_col] = actual_col
                            break
                
                if len(column_mapping) >= 6:  # ìµœì†Œ 6ê°œ ì»¬ëŸ¼ì€ í•„ìš”
                    logger.info("ì»¬ëŸ¼ ë§¤í•‘ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                    df = df.rename(columns=column_mapping)
                else:
                    logger.error("ì¶©ë¶„í•œ ì»¬ëŸ¼ì„ ë§¤í•‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return None
            
            # ë°ì´í„° ì •ë¦¬
            df = df.dropna(subset=['Type', 'Model', 'Status', 'Location'])  # í•„ìˆ˜ í•„ë“œê°€ ë¹„ì–´ìˆëŠ” í–‰ ì œê±°
            
            # ID ì»¬ëŸ¼ì´ ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if 'ID' in df.columns:
                try:
                    df['ID'] = pd.to_numeric(df['ID'], errors='coerce')
                    df = df.dropna(subset=['ID'])
                except:
                    logger.warning("ID ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒˆ IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                    df = df.drop('ID', axis=1)
            
            # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
            if 'Purchase Date' in df.columns:
                df['Purchase Date'] = pd.to_datetime(df['Purchase Date'], errors='coerce')
            
            logger.info(f"ì •ë¦¬ í›„ {len(df)}ê°œì˜ ìœ íš¨í•œ í–‰ì´ ë‚¨ì•˜ìŠµë‹ˆë‹¤.")
            return df
            
        except Exception as e:
            logger.error(f"ì—‘ì…€ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            return None
    
    def validate_data(self, df):
        """ë°ì´í„° ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
        try:
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_columns = ["Type", "Model", "Status", "Location"]
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                logger.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_columns}")
                return False
            
            # ë°ì´í„° íƒ€ì… ê²€ì¦
            valid_types = ['HW', 'SW', 'NW', 'STORAGE']
            valid_statuses = ['ì…ê³ ', 'ëŒ€ê¸°', 'ìš´ì˜', 'ìœ íœ´', 'íê¸°']
            valid_locations = ['ë³¸ì‚¬ ì„œë²„ì‹¤', 'ê°œì¸ì§€ê¸‰', 'í”„ë¡œì íŠ¸ì¥ì†Œ', 'ê¸°íƒ€']
            
            # Type ê²€ì¦
            invalid_types = df[~df['Type'].isin(valid_types)]['Type'].unique()
            if len(invalid_types) > 0:
                logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ Type ê°’ì´ ìˆìŠµë‹ˆë‹¤: {invalid_types}")
                # ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì€ 'ê¸°íƒ€'ë¡œ ë³€ê²½
                df.loc[~df['Type'].isin(valid_types), 'Type'] = 'HW'
            
            # Status ê²€ì¦
            invalid_statuses = df[~df['Status'].isin(valid_statuses)]['Status'].unique()
            if len(invalid_statuses) > 0:
                logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ Status ê°’ì´ ìˆìŠµë‹ˆë‹¤: {invalid_statuses}")
                # ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì€ 'ëŒ€ê¸°'ë¡œ ë³€ê²½
                df.loc[~df['Status'].isin(valid_statuses), 'Status'] = 'ëŒ€ê¸°'
            
            # Location ê²€ì¦
            invalid_locations = df[~df['Location'].isin(valid_locations)]['Location'].unique()
            if len(invalid_locations) > 0:
                logger.warning(f"ìœ íš¨í•˜ì§€ ì•Šì€ Location ê°’ì´ ìˆìŠµë‹ˆë‹¤: {invalid_locations}")
                # ìœ íš¨í•˜ì§€ ì•Šì€ ê°’ì€ 'ê¸°íƒ€'ë¡œ ë³€ê²½
                df.loc[~df['Location'].isin(valid_locations), 'Location'] = 'ê¸°íƒ€'
            
            logger.info("ë°ì´í„° ê²€ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def migrate_data(self, df):
        """ë°ì´í„°ë¥¼ PostgreSQLë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•©ë‹ˆë‹¤."""
        try:
            cursor = self.connection.cursor()
            
            # ê¸°ì¡´ ë°ì´í„° í™•ì¸
            cursor.execute("SELECT COUNT(*) FROM assets")
            existing_count = cursor.fetchone()[0]
            logger.info(f"ê¸°ì¡´ ë°ì´í„° ìˆ˜: {existing_count}")
            
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘
            migrated_count = 0
            skipped_count = 0
            
            for index, row in df.iterrows():
                try:
                    # ë°ì´í„° ì¤€ë¹„
                    asset_data = {
                        'asset_type': row['Type'],
                        'model': str(row['Model']),
                        'purchase_date': row['Purchase Date'] if pd.notna(row['Purchase Date']) else None,
                        'warranty': str(row['Warranty']) if pd.notna(row['Warranty']) else '',
                        'status': row['Status'],
                        'location': row['Location'],
                        'reason': str(row['Reason']) if pd.notna(row['Reason']) else ''
                    }
                    
                    # ì¤‘ë³µ ì²´í¬ (Modelê³¼ Typeìœ¼ë¡œ)
                    cursor.execute(
                        "SELECT id FROM assets WHERE model = %s AND asset_type = %s",
                        (asset_data['model'], asset_data['asset_type'])
                    )
                    
                    if cursor.fetchone():
                        logger.debug(f"ì¤‘ë³µ ë°ì´í„° ê±´ë„ˆë›°ê¸°: {asset_data['model']} ({asset_data['asset_type']})")
                        skipped_count += 1
                        continue
                    
                    # ë°ì´í„° ì‚½ì…
                    insert_query = """
                    INSERT INTO assets (asset_type, model, purchase_date, warranty, status, location, reason)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                    """
                    
                    cursor.execute(insert_query, (
                        asset_data['asset_type'],
                        asset_data['model'],
                        asset_data['purchase_date'],
                        asset_data['warranty'],
                        asset_data['status'],
                        asset_data['location'],
                        asset_data['reason']
                    ))
                    
                    migrated_count += 1
                    
                    if migrated_count % 10 == 0:
                        logger.info(f"ì§„í–‰ë¥ : {migrated_count}/{len(df)}")
                
                except Exception as e:
                    logger.error(f"í–‰ {index} ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
                    skipped_count += 1
                    continue
            
            # ë³€ê²½ì‚¬í•­ ì»¤ë°‹
            self.connection.commit()
            
            logger.info(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {migrated_count}ê°œ ì„±ê³µ, {skipped_count}ê°œ ê±´ë„ˆëœ€")
            
            # ìµœì¢… ë°ì´í„° ìˆ˜ í™•ì¸
            cursor.execute("SELECT COUNT(*) FROM assets")
            final_count = cursor.fetchone()[0]
            logger.info(f"ìµœì¢… ë°ì´í„° ìˆ˜: {final_count}")
            
            cursor.close()
            return migrated_count
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
            self.connection.rollback()
            return 0
    
    def close_connection(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."""
        if self.connection:
            self.connection.close()
            logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def run_migration(self):
        """ì „ì²´ ë§ˆì´ê·¸ë ˆì´ì…˜ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        logger.info("ì—‘ì…€ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        try:
            # 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            if not self.connect_database():
                return False
            
            # 2. ì—‘ì…€ ë°ì´í„° ì½ê¸°
            df = self.read_excel_data()
            if df is None or len(df) == 0:
                logger.error("ì½ì„ ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # 3. ë°ì´í„° ê²€ì¦
            if not self.validate_data(df):
                logger.error("ë°ì´í„° ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return False
            
            # 4. ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
            migrated_count = self.migrate_data(df)
            
            if migrated_count > 0:
                logger.info(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! {migrated_count}ê°œ ë°ì´í„° ì´ì „")
                return True
            else:
                logger.error("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
        finally:
            self.close_connection()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ì—‘ì…€ ë°ì´í„°ë¥¼ PostgreSQLë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•©ë‹ˆë‹¤...")
    print("=" * 60)
    
    # ì„¤ì •
    excel_file_path = input("ì—‘ì…€ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: Asset Management.xlsx): ").strip()
    if not excel_file_path:
        excel_file_path = "Asset Management.xlsx"
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
    print("\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    db_host = input("í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: localhost): ").strip() or "localhost"
    db_port = input("í¬íŠ¸ (ê¸°ë³¸ê°’: 5432): ").strip() or "5432"
    db_name = input("ë°ì´í„°ë² ì´ìŠ¤ëª… (ê¸°ë³¸ê°’: it_asset_db): ").strip() or "it_asset_db"
    db_user = input("ì‚¬ìš©ìëª… (ê¸°ë³¸ê°’: postgres): ").strip() or "postgres"
    db_password = input("ë¹„ë°€ë²ˆí˜¸: ").strip()
    
    if not db_password:
        print("âŒ ë¹„ë°€ë²ˆí˜¸ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")
        return
    
    db_config = {
        'host': db_host,
        'port': int(db_port),
        'database': db_name,
        'user': db_user,
        'password': db_password
    }
    
    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    migrator = ExcelToPostgreSQLMigrator(excel_file_path, db_config)
    
    if migrator.run_migration():
        print("\nğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\nğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
        print("1. PS_Asset_Management.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹œì‘í•˜ì„¸ìš”")
        print("2. ë§ˆì´ê·¸ë ˆì´ì…˜ëœ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”")
    else:
        print("\nâŒ ë§ˆì´ê·¸ë ˆì´ì…˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("ë¡œê·¸ë¥¼ í™•ì¸í•˜ì—¬ ë¬¸ì œë¥¼ íŒŒì•…í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()

